{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "db85391c-b37f-45aa-bafc-5cb57ce81f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install pytest chispa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "60f9f723-bc36-4807-ad28-2e141c8b1cee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "from datetime import date, datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, LongType,\n",
    "    DateType, BooleanType, TimestampType\n",
    ")\n",
    "from chispa.dataframe_comparer import assert_df_equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8b553eab-1123-46af-95e3-b3d0b9efdb6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def sub_transform(sub_df):\n",
    "    sub_df = sub_df.filter(col(\"adsh\").isNotNull() & col(\"cik\").isNotNull() & col(\"name\").isNotNull() & col(\"sic\").isNotNull())\n",
    "\n",
    "    sub_df = sub_df.drop(\"bas1\", \"bas2\", \"countryma\", \"stprma\", \"cityma\", \"zipma\", \"mas1\", \"mas2\", \"countryinc\", \"stprinc\", \"ein\", \"former\", \"changed\", \"afs\", \"wksi\", \"prevrpt\", \"detail\", \"nciks\", \"aciks\")\n",
    "\n",
    "    sub_df = sub_df.withColumn(\"period\", to_date(\"period\", \"yyyyMMdd\"))\n",
    "    sub_df = sub_df.withColumn(\"filed\", to_date(\"filed\", \"yyyyMMdd\"))\n",
    "\n",
    "    sub_df = sub_df.withColumn(\"baph\", regexp_replace(\"baph\", \"[^0-9]\", \"\"))\n",
    "\n",
    "    columns_to_trim = [\"name\", \"countryba\", \"stprba\", \"cityba\", \"zipba\", \"form\", \"instance\"]\n",
    "    for col_name in columns_to_trim:\n",
    "        sub_df = sub_df.withColumn(col_name, trim(col_name))\n",
    "    \n",
    "    sub_df=sub_df.withColumn(\"delay_days\", datediff(col(\"filed\"), col(\"period\")))\n",
    "\n",
    "    sub_df = sub_df.select(\n",
    "        \"adsh\", \"cik\", \"name\", \"sic\", \"countryba\", \"stprba\", \"cityba\", \"zipba\", \"baph\",\n",
    "        \"fye\", \"form\", \"period\", \"fy\", \"fp\", \"filed\", \"delay_days\", \"accepted\", \"instance\"\n",
    "    )\n",
    "    \n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "00597c4c-3f80-4048-ae85-3ece11633f53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"adsh\", StringType(), True),\n",
    "    StructField(\"cik\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"sic\", IntegerType(), True),\n",
    "    StructField(\"countryba\", StringType(), True),\n",
    "    StructField(\"stprba\", StringType(), True),\n",
    "    StructField(\"cityba\", StringType(), True),\n",
    "    StructField(\"zipba\", StringType(), True),\n",
    "    StructField(\"bas1\", StringType(), True),\n",
    "    StructField(\"bas2\", StringType(), True),\n",
    "    StructField(\"baph\", StringType(), True),\n",
    "    StructField(\"countryma\", StringType(), True),\n",
    "    StructField(\"stprma\", StringType(), True),\n",
    "    StructField(\"cityma\", StringType(), True),\n",
    "    StructField(\"zipma\", StringType(), True),\n",
    "    StructField(\"mas1\", StringType(), True),\n",
    "    StructField(\"mas2\", StringType(), True),\n",
    "    StructField(\"countryinc\", StringType(), True),\n",
    "    StructField(\"stprinc\", StringType(), True),\n",
    "    StructField(\"ein\", StringType(), True),\n",
    "    StructField(\"former\", StringType(), True),\n",
    "    StructField(\"changed\", DateType(), True),\n",
    "    StructField(\"afs\", StringType(), True),\n",
    "    StructField(\"wksi\", BooleanType(), True),\n",
    "    StructField(\"fye\", StringType(), True),\n",
    "    StructField(\"form\", StringType(), True),\n",
    "    StructField(\"period\", StringType(), True),\n",
    "    StructField(\"fy\", IntegerType(), True),\n",
    "    StructField(\"fp\", StringType(), True),\n",
    "    StructField(\"filed\", StringType(), True),\n",
    "    StructField(\"accepted\", TimestampType(), True),\n",
    "    StructField(\"prevrpt\", BooleanType(), True),\n",
    "    StructField(\"detail\", BooleanType(), True),\n",
    "    StructField(\"instance\", StringType(), True),\n",
    "    StructField(\"nciks\", IntegerType(), True),\n",
    "    StructField(\"aciks\", StringType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"quarter\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "expected_schema = StructType([\n",
    "    StructField(\"adsh\", StringType(), True),\n",
    "    StructField(\"cik\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"sic\", IntegerType(), True),\n",
    "    StructField(\"countryba\", StringType(), True),\n",
    "    StructField(\"stprba\", StringType(), True),\n",
    "    StructField(\"cityba\", StringType(), True),\n",
    "    StructField(\"zipba\", StringType(), True),\n",
    "    StructField(\"baph\", StringType(), True),\n",
    "    StructField(\"fye\", StringType(), True),\n",
    "    StructField(\"form\", StringType(), True),\n",
    "    StructField(\"period\", DateType(), True),\n",
    "    StructField(\"fy\", IntegerType(), True),\n",
    "    StructField(\"fp\", StringType(), True),\n",
    "    StructField(\"filed\", DateType(), True),\n",
    "    StructField(\"delay_days\", IntegerType(), True),\n",
    "    StructField(\"accepted\", TimestampType(), True),\n",
    "    StructField(\"instance\", StringType(), True)\n",
    "])\n",
    "\n",
    "sample_data = [\n",
    "    # Valid input\n",
    "    (\"0001\", 1000001, \" Test Company \", 1234, \" USA \", \" CA \", \" San Francisco \", \"94105\",\n",
    "     \"addr1\", \"addr2\", \"(123) 456-7890\",\n",
    "     \"USA\", \"CA\", \"NYC\", \"10001\", \"HQ\", \"HQ2\", \"USA\", \"CA\", \"12-3456789\", \"Former Co\",\n",
    "     date(2020, 1, 1), \"AFS\", True, \"1231\", \" 10-K \", \"20240101\", 2024, \"FY\", \"20240131\",\n",
    "     datetime(2024, 2, 1, 10, 0), False, True, \" Instance_1 \", 5, \"ACIKS\", 2024, 1),\n",
    "\n",
    "    # Invalid input (null adsh) -> should be filtered\n",
    "    (None, 1000002, \"Another Co\", 1235, \"USA\", \"NY\", \"New York\", \"10002\", \"111-222\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", None,\n",
    "     \"AFS\", True, \"1231\", \"10-K\", \"20240101\", 2024, \"FY\", \"20240131\", datetime(2024, 2, 1, 10, 0), False, True, \"Instance_2\", 5, \"ACIKS\", 2024, 1),\n",
    "\n",
    "    # Valid input with already clean data (no trimming needed)\n",
    "    (\"0003\", 1000003, \"CleanCo\", 5678, \"USA\", \"TX\", \"Austin\", \"73301\",\"\",\"\", \"9999999999\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\"\", \"\", date(2021, 5, 10),\n",
    " \"AFS\", False, \"0630\", \"10-Q\", \"20230630\", 2023, \"Q2\", \"20230715\", datetime(2023, 7, 20, 9, 0), False, False, \"Instance_3\", 3, \"\", 2023, 2),\n",
    "]\n",
    "\n",
    "expected_data = [\n",
    "    (\"0001\", 1000001, \"Test Company\", 1234, \"USA\", \"CA\", \"San Francisco\", \"94105\", \"1234567890\",\n",
    "     \"1231\", \"10-K\", date(2024, 1, 1), 2024, \"FY\", date(2024, 1, 31), 30, datetime(2024, 2, 1, 10, 0), \"Instance_1\"),\n",
    "\n",
    "    (\"0003\", 1000003, \"CleanCo\", 5678, \"USA\", \"TX\", \"Austin\", \"73301\", \"9999999999\",\n",
    "     \"0630\", \"10-Q\", date(2023, 6, 30), 2023, \"Q2\", date(2023, 7, 15), 15, datetime(2023, 7, 20, 9, 0), \"Instance_3\")\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "df9c61b6-7144-414b-8bd5-60b37ab1b4f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def spark():\n",
    "    return SparkSession.builder.appName(\"SubTransformTests\").getOrCreate()\n",
    "\n",
    "def test_sub_transformation_basic(spark):\n",
    "    print(\"\\nRunning basic sub transformation test...\")\n",
    "    input_df = spark.createDataFrame(sample_data, schema=schema)\n",
    "    expected_df = spark.createDataFrame(expected_data, schema=expected_schema)\n",
    "\n",
    "    result_df = sub_transform(input_df)\n",
    "\n",
    "    try:\n",
    "        assert_df_equality(result_df, expected_df, ignore_nullable=True)\n",
    "        print(\"✅ Basic transformation test passed\")\n",
    "    except AssertionError as e:\n",
    "        print(\"❌ Basic transformation test failed\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "def test_required_columns_filtering(spark):\n",
    "    print(\"\\nRunning required columns filtering test...\")\n",
    "    test_data = [  # missing adsh and name\n",
    "        (None, 1000003, None, None, \"USA\", \"TX\", \"Austin\", \"73301\", None, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", None,\n",
    "         \"AFS\", True, \"1231\", \"10-K\", \"20240101\", 2024, \"FY\", \"20240131\", datetime(2024, 2, 1), False, True, \"Instance\", 1, \"ACIKS\", 2024, 1)\n",
    "    ]\n",
    "    df = spark.createDataFrame(test_data, schema=schema)\n",
    "    result_df = sub_transform(df)\n",
    "\n",
    "    try:\n",
    "        assert result_df.count() == 0\n",
    "        print(\"✅ Required columns filtering test passed\")\n",
    "    except AssertionError:\n",
    "        print(\"❌ Required columns filtering test failed\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def test_delay_days_calculation(spark):\n",
    "    print(\"\\nRunning delay days calculation test...\")\n",
    "    test_data = [\n",
    "        (\"0002\", 1000002, \"Company B\", 9999, \"USA\", \"IL\", \"Chicago\", \"60601\", \"123-999-4567\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", None,\n",
    "         \"AFS\", False, \"0630\", \"10-Q\", \"20240101\", 2024, \"Q1\", \"20240120\", datetime(2024, 1, 21), False, False, \"Instance_2\", 5, \"ACIKS\", 2024, 1)\n",
    "    ]\n",
    "    df = spark.createDataFrame(test_data, schema=schema)\n",
    "    result_df = sub_transform(df)\n",
    "\n",
    "    try:\n",
    "        assert result_df.first()[\"delay_days\"] == 19\n",
    "        print(\"✅ Delay days calculation test passed\")\n",
    "    except AssertionError:\n",
    "        print(\"❌ Delay days calculation test failed\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20b2087a-80f2-47ea-9d37-199655e8e294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_session = spark()\n",
    "test_sub_transformation_basic(spark_session)\n",
    "test_required_columns_filtering(spark_session)\n",
    "test_delay_days_calculation(spark_session)\n",
    "print(\"\\nAll tests completed ✅\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "testing_submissions_transformations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
