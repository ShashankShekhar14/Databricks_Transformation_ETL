{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "148af3e0-d0a0-4422-b3c8-d5c5b4781155",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Load `pre.txt` from Bronze Layer\n",
    "\n",
    "We read the raw `pre.txt` file from the Bronze Delta table. This file contains metadata about presentation line items such as balance sheet or income statement entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89cf228-4a4e-4744-8094-b76dd6efaea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58e0a5c5-2cdb-4b8c-9ac5-7c55c02b766d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pre_df = spark.read.option(\"header\", True) \\\n",
    "                   .option(\"delimiter\", \"\\t\") \\\n",
    "                   .option(\"inferSchema\", True) \\\n",
    "                   .option('format','delta')\\\n",
    "                   .load(\"dbfs:/user/hive/warehouse/bronzes.db/presentations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3511c6e-c179-495a-af33-b06f084f89d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Impute Missing `stmt` Column\n",
    "\n",
    "To handle missing values in the `stmt` column:\n",
    "- Find the most frequent `stmt` for each `tag`\n",
    "- Use it to fill nulls\n",
    "- Fallback to \"UN\" (Unclassified) if still null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb22d98f-bf3d-4502-b00d-c67d1edb190b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame, Window\n",
    "from pyspark.sql.functions import col, when, row_number\n",
    "\n",
    "def impute_pre_stmt(df_pre: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Impute nulls in the PRE DataFrame’s stmt column by:\n",
    "      1. Computing each tag’s most frequent statement type (mode) across filings.\n",
    "      2. Filling null stmt values with that per-tag mode.\n",
    "      3. As a final fallback, assigning 'UN' (Unclassifiable) to any remaining nulls.\n",
    "\n",
    "    Parameters:\n",
    "        df_pre (DataFrame): Cleaned PRE DataFrame containing at least 'tag' and 'stmt'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with no nulls in stmt.\n",
    "    \"\"\"\n",
    "    # 1) Build per-tag mode lookup for stmt\n",
    "    tag_mode_stmt = (\n",
    "        df_pre\n",
    "          .filter(col(\"stmt\").isNotNull())\n",
    "          .groupBy(\"tag\", \"stmt\")\n",
    "          .count()\n",
    "          .withColumn(\n",
    "              \"rn\",\n",
    "              row_number().over(\n",
    "                  Window.partitionBy(\"tag\")\n",
    "                        .orderBy(col(\"count\").desc())\n",
    "              )\n",
    "          )\n",
    "          .filter(col(\"rn\") == 1)\n",
    "          .select(\"tag\", col(\"stmt\").alias(\"stmt_mode\"))\n",
    "    )\n",
    "\n",
    "    # 2) Left-join and fill with per-tag mode\n",
    "    df_filled = (\n",
    "        df_pre\n",
    "          .join(tag_mode_stmt, on=\"tag\", how=\"left\")\n",
    "          .withColumn(\n",
    "              \"stmt\",\n",
    "              when(col(\"stmt\").isNull(), col(\"stmt_mode\"))\n",
    "              .otherwise(col(\"stmt\"))\n",
    "          )\n",
    "          .drop(\"stmt_mode\")\n",
    "    )\n",
    "\n",
    "    # 3) Final fallback: assign 'UN' to any still-null stmt\n",
    "    df_result = df_filled.withColumn(\n",
    "        \"stmt\",\n",
    "        when(col(\"stmt\").isNull(), \"UN\")\n",
    "        .otherwise(col(\"stmt\"))\n",
    "    )\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb010547-1207-430b-99ea-66e4ef2f4185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pre_df=impute_pre_stmt(pre_df)\n",
    "display(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f074660-3ff3-45d2-af79-3e5bfb21f6f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pre_df.filter(col(\"stmt\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0de09ef0-1b99-46c0-a3f7-cb0239c67f6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Impute Missing `plabel` Using `tag`\n",
    "\n",
    "If `plabel` (presentation label) is null, generate it from `tag`:\n",
    "- Add space between lowercase-uppercase boundaries\n",
    "- Convert to title case for readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1558aa5d-8836-4d9f-951c-e51e12bb6f59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, when, regexp_replace, initcap\n",
    "\n",
    "def impute_plabel_from_tag(df_pre: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Fill null 'plabel' values in a PRE DataFrame by deriving a label from the 'tag':\n",
    "      - Inserts spaces before capital letters that follow lowercase letters\n",
    "      - Converts the result to title case\n",
    "\n",
    "    Parameters:\n",
    "        df_pre (DataFrame): Cleaned PRE DataFrame containing 'tag' and 'plabel'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with no nulls in 'plabel'.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        df_pre\n",
    "          .withColumn(\n",
    "              \"plabel\",\n",
    "              when(\n",
    "                  col(\"plabel\").isNull(),\n",
    "                  initcap(\n",
    "                      regexp_replace(col(\"tag\"), \"([a-z])([A-Z])\", \"$1 $2\")\n",
    "                  )\n",
    "              )\n",
    "              .otherwise(col(\"plabel\"))\n",
    "          )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc3672e-bfe0-41f3-bfc4-0b333f4f966c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pre_df=impute_plabel_from_tag(pre_df)\n",
    "display(pre_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ac6b1b1-3afb-46b1-b408-2169631f3136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Confirm `plabel` Is Fully Filled\n",
    "\n",
    "Check if any null values remain in `plabel`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f87aa0bb-27ce-443e-bfdf-2919c651e96c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pre_df.filter(col(\"plabel\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c16bf45-c648-4c6f-a72b-9d0923b55f53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Final Cleaning & Column Selection\n",
    "\n",
    "- Dropped unused or noisy columns (`inpth`, `rfile`, `negating`, `year`, `quarter`)\n",
    "- Trimmed leading/trailing spaces\n",
    "- Ensured `stmt` is not null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78120af8-32f4-401e-a8ae-a36ff16cd39b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def pre_transform(pre_df):\n",
    "    pre_df=pre_df.drop(\"inpth\", \"rfile\", \"negating\")\n",
    "    pre_df=pre_df.filter(col(\"stmt\").isNotNull())\n",
    "    pre_df = pre_df.drop(\"year\",\"quarter\")\n",
    "    columns_to_trim = [\"adsh\", \"stmt\", \"tag\", \"version\", \"plabel\"]\n",
    "    for col_name in columns_to_trim:\n",
    "        pre_df = pre_df.withColumn(col_name, trim(col_name))\n",
    "    return pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34192a9e-a772-45d0-843c-2814afcbbd7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pre_df=pre_transform(pre_df)\n",
    "# Display the first 20 rows\n",
    "display(pre_df.limit(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e96f0d89-51be-45a9-8191-94d03067dd11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Select Final Columns for Silver Table\n",
    "\n",
    "Selected relevant cleaned columns and finalized schema:\n",
    "- adsh, report, line, stmt, tag, version, plabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486c6a8d-d631-4d4b-bcd8-e98e949c0abd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pre_df = pre_df.select(\"adsh\", \"report\", \"line\", \"stmt\", \"tag\", \"version\", \"plabel\")\n",
    "display(pre_df.limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b6baaf-ceb0-448f-bf63-f4c0df3acf95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "drop table if exists silver.presentations;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdfef2b6-8c00-4f71-a091-5b8d5ba024f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  Save Cleaned `pre.txt` to Silver Delta Table\n",
    "\n",
    "The transformed presentation data is saved to the Silver layer for downstream analytics or reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b1945c-bae8-454c-b2f0-b5992098f20b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pre_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"silver.presentations\")\n",
    "pre_df_loaded = spark.read.format(\"delta\").table(\"silver.presentations\")\n",
    "display(pre_df_loaded)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7525539422956086,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver_Presentations_Transformations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
